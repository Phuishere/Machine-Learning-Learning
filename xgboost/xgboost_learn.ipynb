{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anxiety_level</th>\n",
       "      <th>self_esteem</th>\n",
       "      <th>mental_health_history</th>\n",
       "      <th>depression</th>\n",
       "      <th>headache</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>breathing_problem</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>living_conditions</th>\n",
       "      <th>...</th>\n",
       "      <th>basic_needs</th>\n",
       "      <th>academic_performance</th>\n",
       "      <th>study_load</th>\n",
       "      <th>teacher_student_relationship</th>\n",
       "      <th>future_career_concerns</th>\n",
       "      <th>social_support</th>\n",
       "      <th>peer_pressure</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>bullying</th>\n",
       "      <th>stress_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anxiety_level  self_esteem  mental_health_history  depression  headache  \\\n",
       "0             14           20                      0          11         2   \n",
       "1             15            8                      1          15         5   \n",
       "2             12           18                      1          14         2   \n",
       "3             16           12                      1          15         4   \n",
       "4             16           28                      0           7         2   \n",
       "\n",
       "   blood_pressure  sleep_quality  breathing_problem  noise_level  \\\n",
       "0               1              2                  4            2   \n",
       "1               3              1                  4            3   \n",
       "2               1              2                  2            2   \n",
       "3               3              1                  3            4   \n",
       "4               3              5                  1            3   \n",
       "\n",
       "   living_conditions  ...  basic_needs  academic_performance  study_load  \\\n",
       "0                  3  ...            2                     3           2   \n",
       "1                  1  ...            2                     1           4   \n",
       "2                  2  ...            2                     2           3   \n",
       "3                  2  ...            2                     2           4   \n",
       "4                  2  ...            3                     4           3   \n",
       "\n",
       "   teacher_student_relationship  future_career_concerns  social_support  \\\n",
       "0                             3                       3               2   \n",
       "1                             1                       5               1   \n",
       "2                             3                       2               2   \n",
       "3                             1                       4               1   \n",
       "4                             1                       2               1   \n",
       "\n",
       "   peer_pressure  extracurricular_activities  bullying  stress_level  \n",
       "0              3                           3         2             1  \n",
       "1              4                           5         5             2  \n",
       "2              3                           2         2             1  \n",
       "3              4                           4         5             2  \n",
       "4              5                           0         5             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data: rxnach/student-stress-factors-a-comprehensive-analysis\n",
    "data_path = \"./StressLevelDataset.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyse models in comparison with XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier, GradientBoostingClassifier,\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# Models\n",
    "logistic_model = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    max_iter=100,\n",
    "    verbose=False,\n",
    ")\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=250)\n",
    "ada_boost_model = AdaBoostClassifier(n_estimators=250)  # thử k=5 trước\n",
    "gradient_boost_model = GradientBoostingClassifier(n_estimators=250)\n",
    "xg_boost_model = xgb.XGBClassifier(\n",
    "    n_estimators = 250\n",
    ")\n",
    "\n",
    "# Model dict\n",
    "models = {\n",
    "    \"Logistic Regression\": logistic_model,\n",
    "    \"Decision Tree\": decision_tree_model,\n",
    "    \"Random Forest\": random_forest_model,\n",
    "    \"Ada Boost\": ada_boost_model,\n",
    "    \"Gradient Boost\": gradient_boost_model,\n",
    "    \"XGBoost\": xg_boost_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression took 62.87 miliseconds to train.\n",
      "Decision Tree took 4.39 miliseconds to train.\n",
      "Random Forest took 428.27 miliseconds to train.\n",
      "Ada Boost took 507.25 miliseconds to train.\n",
      "Gradient Boost took 1503.77 miliseconds to train.\n",
      "XGBoost took 496.62 miliseconds to train.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Evaluating models\n",
    "# TODO: More rigorous stuff here (latency, throughput, FLOPs)\n",
    "for model_name, model in models.items():\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(f\"{model_name} took {round((end - start)*1000, 2)} miliseconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def validation_and_visualize(\n",
    "    model, model_name: str,\n",
    "    X_test, y_test,\n",
    "    visualized: bool = True,\n",
    "):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if visualized:\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        \n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Dự đoán\")\n",
    "        plt.ylabel(\"Thực tế\")\n",
    "        plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8818181818181818\n",
      "Accuracy: 0.8863636363636364\n",
      "Accuracy: 0.8727272727272727\n",
      "Accuracy: 0.8772727272727273\n",
      "Accuracy: 0.8818181818181818\n",
      "Accuracy: 0.8681818181818182\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    validation_and_visualize(\n",
    "        model, model_name,\n",
    "        X_test = X_test, y_test = y_test,\n",
    "        visualized=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In-depth stuff of xgboost lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main stuff here\n",
    "'''\n",
    "Official Doc: https://xgboost.readthedocs.io\n",
    "Content:\n",
    "    - Matrix dataset setting\n",
    "    - Param list / dict\n",
    "    - Training\n",
    "    - Inferencing and prediction\n",
    "    - Plotting importance and stuff\n",
    "    - Dumping the model and its feature map into txt file\n",
    "    - Save / load a model\n",
    "'''\n",
    "import xgboost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the data matrix (look up doc for supported data types)\n",
    "try:\n",
    "    # Load from file\n",
    "    dtrain = xgb.DMatrix('train.buffer')\n",
    "    dtest = xgboost.DMatrix('test.buffer')\n",
    "except:\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dtrain.save_binary('train.buffer')\n",
    "    dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "    dtest.save_binary('test.buffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter list\n",
    "param = {\n",
    "    'max_depth': 2,\n",
    "    \n",
    "    'eta': 1, # Learning rate\n",
    "    'lambda': 0.2, # L2 regularizer rate\n",
    "    'alpha': 0.2, # L1 regularizer rate (sparse repr.)\n",
    "\n",
    "    'objective': 'multi:softprob', # Objective could be 'binary:logistic', 'multi:softmax' but would not work well with AUC\n",
    "    'num_class': 3,\n",
    "    'eval_metric': ['mlogloss', 'merror', 'auc'], # logloss is only for binary\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "# Validation set (code from doc)\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.36031\ttrain-merror:0.10000\ttrain-auc:0.98706\teval-mlogloss:0.38590\teval-merror:0.12273\teval-auc:0.97487\n",
      "[1]\ttrain-mlogloss:0.24637\ttrain-merror:0.09091\ttrain-auc:0.98971\teval-mlogloss:0.27581\teval-merror:0.12727\teval-auc:0.98555\n",
      "[2]\ttrain-mlogloss:0.20571\ttrain-merror:0.08295\ttrain-auc:0.99071\teval-mlogloss:0.26070\teval-merror:0.12273\teval-auc:0.98306\n",
      "[3]\ttrain-mlogloss:0.18537\ttrain-merror:0.07841\ttrain-auc:0.99159\teval-mlogloss:0.25807\teval-merror:0.12727\teval-auc:0.98271\n",
      "[4]\ttrain-mlogloss:0.16623\ttrain-merror:0.06591\ttrain-auc:0.99329\teval-mlogloss:0.26412\teval-merror:0.13636\teval-auc:0.98213\n",
      "[5]\ttrain-mlogloss:0.15318\ttrain-merror:0.05568\ttrain-auc:0.99482\teval-mlogloss:0.26209\teval-merror:0.12727\teval-auc:0.98261\n",
      "[6]\ttrain-mlogloss:0.14671\ttrain-merror:0.04318\ttrain-auc:0.99531\teval-mlogloss:0.25589\teval-merror:0.11818\teval-auc:0.98313\n",
      "[7]\ttrain-mlogloss:0.13660\ttrain-merror:0.05000\ttrain-auc:0.99613\teval-mlogloss:0.25698\teval-merror:0.10909\teval-auc:0.98375\n",
      "[8]\ttrain-mlogloss:0.12846\ttrain-merror:0.04205\ttrain-auc:0.99666\teval-mlogloss:0.24636\teval-merror:0.11818\teval-auc:0.98465\n",
      "[9]\ttrain-mlogloss:0.11871\ttrain-merror:0.03750\ttrain-auc:0.99737\teval-mlogloss:0.24717\teval-merror:0.11364\teval-auc:0.98381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Train model\n",
    "num_round = 10\n",
    "bst = xgb.train(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    evallist,\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save and load models\n",
    "# Save model\n",
    "bst.save_model('xgb_0001.json') # could be .model, .json, etc.\n",
    "\n",
    "# Get model\n",
    "bst.load_model('xgb_0001.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation\n",
    "# Use predict() method with DMatrix (converted to supported type)\n",
    "y_pred = bst.predict(dtest).argmax(axis = 1)\n",
    "\n",
    "# Accuracy and Confusion Matrix\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Dự đoán\")\n",
    "plt.ylabel(\"Thực tế\")\n",
    "plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Other stuff (subsampling, summarizing, plot error bar, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Best: 0.886364 using {'subsample': 0.7}\n",
      "0.884545 (0.027589) with: {'subsample': 0.1}\n",
      "0.884545 (0.024747) with: {'subsample': 0.2}\n",
      "0.875455 (0.014113) with: {'subsample': 0.3}\n",
      "0.881818 (0.022268) with: {'subsample': 0.4}\n",
      "0.880000 (0.025324) with: {'subsample': 0.5}\n",
      "0.873636 (0.033141) with: {'subsample': 0.6}\n",
      "0.886364 (0.025793) with: {'subsample': 0.7}\n",
      "0.880909 (0.023514) with: {'subsample': 0.8}\n",
      "0.885455 (0.023070) with: {'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Source: https://vtitech.vn/xgboost-bai-14-tuning-subsample/\n",
    "'''\n",
    "Content:\n",
    "    - XGBoost model\n",
    "    - Subsampling and K-fold with Grid Search\n",
    "    - Summarizing results\n",
    "    - Plot error bar (currently unavailable in this notebook)\n",
    "'''\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# encode string class values as integers\n",
    "label_encoded_y = LabelEncoder().fit_transform(y) # y chung\n",
    "\n",
    "# grid search\n",
    "grid_model = XGBClassifier()\n",
    "subsample = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "param_grid = dict(subsample=subsample)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(grid_model, param_grid, scoring=\"accuracy\", n_jobs=1, cv=kfold, verbose=1)\n",
    "grid_result = grid_search.fit(X, label_encoded_y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# plot\n",
    "pyplot.errorbar(subsample, means, yerr=stds)\n",
    "pyplot.title(\"XGBoost subsample vs accuracy\")\n",
    "pyplot.xlabel('subsample')\n",
    "pyplot.ylabel('Accuracy')\n",
    "pyplot.savefig('subsample.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
